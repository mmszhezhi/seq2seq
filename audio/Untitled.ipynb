{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n",
      "0.10.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "_SAMPLE_DIR = \"_sample_data\"\n",
    "\n",
    "SAMPLE_WAV_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav\"\n",
    "SAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, \"steam.wav\")\n",
    "\n",
    "SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n",
    "SAMPLE_RIR_PATH = os.path.join(_SAMPLE_DIR, \"rir.wav\")\n",
    "\n",
    "SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "SAMPLE_WAV_SPEECH_PATH = os.path.join(_SAMPLE_DIR, \"speech.wav\")\n",
    "\n",
    "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n",
    "SAMPLE_NOISE_PATH = os.path.join(_SAMPLE_DIR, \"bg.wav\")\n",
    "\n",
    "os.makedirs(_SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "def _fetch_data():\n",
    "  uri = [\n",
    "    (SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n",
    "    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n",
    "    (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n",
    "    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
    "  ]\n",
    "  for url, path in uri:\n",
    "    with open(path, 'wb') as file_:\n",
    "      file_.write(requests.get(url).content)\n",
    "\n",
    "_fetch_data()\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.extend([\n",
    "      [\"lowpass\", f\"{resample // 2}\"],\n",
    "      [\"rate\", f'{resample}'],\n",
    "    ])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "def get_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n",
    "\n",
    "def get_speech_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "    axes[c].grid(True)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "    if ylim:\n",
    "      axes[c].set_ylim(ylim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "  if src:\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", src)\n",
    "    print(\"-\" * 10)\n",
    "  if sample_rate:\n",
    "    print(\"Sample Rate:\", sample_rate)\n",
    "  print(\"Shape:\", tuple(waveform.shape))\n",
    "  print(\"Dtype:\", waveform.dtype)\n",
    "  print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "  print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "  print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "  print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "  print()\n",
    "  print(waveform)\n",
    "  print()\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "  if not processed:\n",
    "    return rir_raw, sample_rate\n",
    "  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "  rir = rir / torch.norm(rir, p=2)\n",
    "  rir = torch.flip(rir, [1])\n",
    "  return rir, sample_rate\n",
    "\n",
    "def get_noise_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loaded-identification",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torchaudio.sox_effects.sox_effects.apply_effects_file requires sox",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7982b4e8ef16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwaveform1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Define effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m effects = [\n",
      "\u001b[1;32m<ipython-input-4-b909be141ffc>\u001b[0m in \u001b[0;36mget_sample\u001b[1;34m(resample)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_get_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAMPLE_WAV_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_speech_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b909be141ffc>\u001b[0m in \u001b[0;36m_get_sample\u001b[1;34m(path, resample)\u001b[0m\n\u001b[0;32m     45\u001b[0m       \u001b[1;33m[\u001b[0m\u001b[1;34m\"rate\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{resample}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     ])\n\u001b[1;32m---> 47\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msox_effects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_effects_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\envs\\pro\\lib\\site-packages\\torchaudio\\_internal\\module_utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{func.__module__}.{func.__name__} requires sox'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torchaudio.sox_effects.sox_effects.apply_effects_file requires sox"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "waveform1, sample_rate1 = get_sample(resample=16000)\n",
    "\n",
    "# Define effects\n",
    "effects = [\n",
    "  [\"lowpass\", \"-1\", \"300\"], # apply single-pole lowpass filter\n",
    "  [\"speed\", \"0.8\"],  # reduce the speed\n",
    "                     # This only changes sample rate, so it is necessary to\n",
    "                     # add `rate` effect with original sample rate after this.\n",
    "  [\"rate\", f\"{sample_rate1}\"],\n",
    "  [\"reverb\", \"-w\"],  # Reverbration gives some dramatic feeling\n",
    "]\n",
    "\n",
    "# Apply effects\n",
    "waveform2, sample_rate2 = torchaudio.sox_effects.apply_effects_tensor(\n",
    "    waveform1, sample_rate1, effects)\n",
    "\n",
    "plot_waveform(waveform1, sample_rate1, title=\"Original\", xlim=(-.1, 3.2))\n",
    "plot_waveform(waveform2, sample_rate2, title=\"Effects Applied\", xlim=(-.1, 3.2))\n",
    "print_stats(waveform1, sample_rate=sample_rate1, src=\"Original\")\n",
    "print_stats(waveform2, sample_rate=sample_rate2, src=\"Effects Applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-prefix",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
